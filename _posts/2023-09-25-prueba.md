---
title: "RESCUE PEOPLE"
date: 2023-09-12
---

Implementación de una solución para el ejercicio 
<a href="https://jderobot.github.io/RoboticsAcademy/exercises/Drones/rescue_people"> Rescue People </a>
de Unibotics.
En este caso tenemos un dron totalmente controlable con el cual tenemos que localizar un grupo de 6 personas que estan en el mar. Tenemos la localizacion aproximada de las personas y la localizacion del barco, ambos en formato UTM.

Primero realizamso una conversion de las coordenadas UTM a nuestro marco local de coordenadas. 
Siguiendo la siguiente formula (ref:
<a href="https://stackoverflow.com/questions/639695/how-to-convert-latitude-or-longitude-to-meters"> lat and long to meters </a>)
Length in km of 1° of latitude = always 111.32 km
Length in km of 1° of longitude = 40075 km * cos( latitude ) / 360

podemos obtener la equivalencia de las coordenadas UTM a nuestro marco local. Obteniendo esto, el movimiento del dron es bastante sencillo comandandolo con la funcion set_cmd_pos de la libreria HAL al punto calculado. 

Una vez nos encontramos en la zona de las personas, realizamos un movimiento en espiral con el dron e identificamos las caras de  las personas. 

En este caso se ha preferido reconocer las caras utilizando un filtro de color y por tamaño de la cara. De esta manera podemos sobrevolar mucho mas alto la zona y detectar en mucho menos tiempo las 6 personas, en comparacion a reconocer las caras utilizando HaasCascade, ya que este metodo necesita que la cara este bastante cerca de la camara. Por otro lado, es mas realista realizar una busqueda con mucha mas altura para poder abarcar una zona mas amplia en menos tiempo.

Para poder calcular la posicion de las caras desde una altitud bastante elevada (15 metros) calculamos la posicion 3d de las caras detectadas desde la imagen 2d. 

![Pasted image](https://github.com/JhonDL/robotica_de_servicio/assets/60139647/09b28f96-4c80-4e3a-a544-dbda3360b1ba)

En el diagrama superior podemos ver que estamos considerando el eje z = altura dron.

<img width="699" alt="image" src="https://github.com/JhonDL/robotica_de_servicio/assets/60139647/54374234-be15-4f0e-8ca6-cae1643ea815">
En el diagrama superior vemos por otro lado, como se puede calcular la posicion 3d sabiendo la distancia del eje z (cosa que en este caso conocemos) y su posicion x e y en la imagen digital. 

De esta manera, conocemos la distancia en eje X e Y desde el marco de referencia del dron a la que esta viendo las caras detectadas. 

Tambien se ha añadido ciertas funcionalidades al dron como una bateria simulada y un mecanismo de auto reanudar, de tal manera que cuando se queda sin bateria pueda volver a cargar y continuar la busqueda donde lo habia dejado. 

[https://www.youtube.com/watch?v=EpXtM8h4mCw]

---
Referencias:

  <a href="https://stackoverflow.com/questions/639695/how-to-convert-latitude-or-longitude-to-meters"> lat and long to meters </a>

  <a href="https://www.geeksforgeeks.org/mapping-coordinates-from-3d-to-2d-using-opencv-python/"> Mapping coordinates from 3d to 2d </a>
